{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q torch torchvision torchaudio pillow tqdm matplotlib numpy pandas\n",
        "\n",
        "import os, random, string, math, sys, time, urllib.request, shutil\n",
        "from pathlib import Path\n",
        "from PIL import Image, ImageFont, ImageDraw, ImageFilter, ImageOps, ImageEnhance\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm.auto import tqdm\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "\n",
        "# ---------------- Config / hyperparameters ----------------\n",
        "seed = 42\n",
        "random.seed(seed)\n",
        "np.random.seed(seed)\n",
        "torch.manual_seed(seed)\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Device:\", device)\n",
        "\n",
        "# dataset sizes (adjust for runtime)\n",
        "NUM_TRAIN = 8000\n",
        "NUM_VAL   = 1500\n",
        "NUM_TEST  = 1500\n",
        "\n",
        "# image size (W x H)\n",
        "IMG_W, IMG_H = 160, 32\n",
        "\n",
        "# text length constraints\n",
        "MIN_LEN, MAX_LEN = 3, 12\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS = 12\n",
        "LR = 1e-3\n",
        "\n",
        "# fonts directory\n",
        "FONTS_DIR = Path(\"fonts\")\n",
        "FONTS_DIR.mkdir(exist_ok=True)\n",
        "\n",
        "# characters allowed: lowercase + digits\n",
        "CHARS = string.ascii_lowercase + string.digits\n",
        "\n",
        "# mapping to/from idx for CTC (blank will be 0)\n",
        "char_list = list(CHARS)\n",
        "idx_to_char = {i+1: ch for i, ch in enumerate(char_list)}\n",
        "char_to_idx = {ch: i+1 for i, ch in enumerate(char_list)}\n",
        "BLANK_IDX = 0\n",
        "\n",
        "# ---------------- Download fonts ----------------\n",
        "font_urls = [\n",
        "    \"https://github.com/google/fonts/raw/main/apache/roboto/Roboto-Regular.ttf\",\n",
        "    \"https://github.com/google/fonts/raw/main/apache/opensans/OpenSans-Regular.ttf\",\n",
        "    \"https://github.com/google/fonts/raw/main/apache/inconsolata/Inconsolata-Regular.ttf\",\n",
        "]\n",
        "downloaded_fonts = []\n",
        "for i, url in enumerate(font_urls):\n",
        "    fname = FONTS_DIR / f\"font_{i}.ttf\"\n",
        "    try:\n",
        "        urllib.request.urlretrieve(url, fname)\n",
        "        downloaded_fonts.append(str(fname))\n",
        "    except Exception as e:\n",
        "        print(f\"Font download failed for {url}: {e}\")\n",
        "\n",
        "if len(downloaded_fonts) == 0:\n",
        "    print(\"No fonts downloaded â€” will use default PIL font.\")\n",
        "    downloaded_fonts = [None]\n",
        "else:\n",
        "    print(\"Downloaded fonts:\", downloaded_fonts)\n",
        "\n",
        "# ---------------- Word pool ----------------\n",
        "words = []\n",
        "try:\n",
        "    with open(\"/usr/share/dict/words\", \"r\") as f:\n",
        "        for w in f:\n",
        "            w = w.strip().lower()\n",
        "            if MIN_LEN <= len(w) <= MAX_LEN and all(ch in CHARS for ch in w):\n",
        "                words.append(w)\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "if len(words) < 500:\n",
        "    letters = string.ascii_lowercase + string.digits\n",
        "    for _ in range(8000):\n",
        "        L = random.randint(MIN_LEN, MAX_LEN)\n",
        "        words.append(\"\".join(random.choices(letters, k=L)))\n",
        "words = list(set(words))\n",
        "print(\"Word pool size:\", len(words))\n",
        "\n",
        "# ---------------- Renderer (uses textbbox) ----------------\n",
        "def render_text_image(text, img_w=IMG_W, img_h=IMG_H):\n",
        "    bg = Image.new(\"L\", (img_w, img_h), color=255)\n",
        "    draw = ImageDraw.Draw(bg)\n",
        "\n",
        "    font_path = random.choice(downloaded_fonts)\n",
        "    if font_path is None:\n",
        "        font = ImageFont.load_default()\n",
        "    else:\n",
        "        size = random.randint(int(img_h*0.6), int(img_h*0.9))\n",
        "        try:\n",
        "            font = ImageFont.truetype(font_path, size=size)\n",
        "        except Exception:\n",
        "            font = ImageFont.load_default()\n",
        "\n",
        "    bbox = draw.textbbox((0, 0), text, font=font)\n",
        "    tw = bbox[2] - bbox[0]\n",
        "    th = bbox[3] - bbox[1]\n",
        "\n",
        "    if tw > img_w - 10 and hasattr(font, \"size\") and font.size is not None:\n",
        "        scale = (img_w - 10) / tw\n",
        "        new_size = max(8, int(font.size * scale))\n",
        "        try:\n",
        "            font = ImageFont.truetype(font_path, size=new_size)\n",
        "            bbox = draw.textbbox((0, 0), text, font=font)\n",
        "            tw = bbox[2] - bbox[0]\n",
        "            th = bbox[3] - bbox[1]\n",
        "        except Exception:\n",
        "            pass\n",
        "\n",
        "    x = max(2, (img_w - tw)//2 + random.randint(-4, 4))\n",
        "    y = max(0, (img_h - th)//2 + random.randint(-2, 2))\n",
        "    ink = random.randint(0, 30)\n",
        "    draw.text((x, y), text, font=font, fill=ink)\n",
        "\n",
        "    if random.random() < 0.2:\n",
        "        bg = bg.filter(ImageFilter.GaussianBlur(radius=random.uniform(0.2, 1.0)))\n",
        "    if random.random() < 0.05:\n",
        "        bg = ImageOps.invert(bg)\n",
        "        if random.random() < 0.5:\n",
        "            bg = ImageOps.invert(bg)\n",
        "    enh = ImageEnhance.Contrast(bg)\n",
        "    bg = enh.enhance(random.uniform(0.9, 1.15))\n",
        "\n",
        "    return bg\n",
        "\n",
        "# ---------------- Dataset & collate ----------------\n",
        "class SyntheticWordsDataset(Dataset):\n",
        "    def __init__(self, words_pool, size):\n",
        "        self.words_pool = words_pool\n",
        "        self.size = size\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        w = random.choice(self.words_pool)\n",
        "        img = render_text_image(w)\n",
        "        arr = np.array(img).astype(np.float32) / 255.0  # H x W\n",
        "        tensor = torch.from_numpy(arr).unsqueeze(0)    # 1 x H x W\n",
        "        target_idxs = [char_to_idx[ch] for ch in w]\n",
        "        target_tensor = torch.tensor(target_idxs, dtype=torch.long)\n",
        "        return tensor, target_tensor, w, img  # also return PIL image for saving examples\n",
        "\n",
        "def collate_fn(batch):\n",
        "    images, targets, target_strs, pil_images = zip(*batch)\n",
        "    images = torch.stack(images, dim=0)\n",
        "    target_lengths = torch.tensor([t.numel() for t in targets], dtype=torch.long)\n",
        "    if len(targets) > 0:\n",
        "        targets_concat = torch.cat(targets)\n",
        "    else:\n",
        "        targets_concat = torch.tensor([], dtype=torch.long)\n",
        "    return images, targets_concat, target_lengths, target_strs, pil_images\n",
        "\n",
        "train_ds = SyntheticWordsDataset(words, NUM_TRAIN)\n",
        "val_ds   = SyntheticWordsDataset(words, NUM_VAL)\n",
        "test_ds  = SyntheticWordsDataset(words, NUM_TEST)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
        "val_loader   = DataLoader(val_ds,   batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds,  batch_size=BATCH_SIZE, shuffle=False, collate_fn=collate_fn, num_workers=2, pin_memory=True)\n",
        "\n",
        "# ---------------- CRNN model ----------------\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, img_h, num_classes, cnn_out=256, rnn_hidden=256, n_rnn_layers=2):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, 1, 1), nn.BatchNorm2d(64), nn.ReLU(True),\n",
        "            nn.MaxPool2d((2,2)),            # H/2, W/2\n",
        "            nn.Conv2d(64, 128, 3, 1, 1), nn.BatchNorm2d(128), nn.ReLU(True),\n",
        "            nn.MaxPool2d((2,2)),            # H/4, W/4\n",
        "            nn.Conv2d(128, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(True),\n",
        "            nn.Conv2d(256, 256, 3, 1, 1), nn.BatchNorm2d(256), nn.ReLU(True),\n",
        "            nn.MaxPool2d((1,2)),            # H/4, W/8 (width halved)\n",
        "            nn.Conv2d(256, cnn_out, 3, 1, 1), nn.BatchNorm2d(cnn_out), nn.ReLU(True),\n",
        "        )\n",
        "        reduced_h = img_h // 4\n",
        "        rnn_input_size = cnn_out * reduced_h\n",
        "        self.rnn = nn.LSTM(input_size=rnn_input_size, hidden_size=rnn_hidden, num_layers=n_rnn_layers,\n",
        "                           bidirectional=True, batch_first=False)\n",
        "        self.fc = nn.Linear(rnn_hidden*2, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.conv(x)           # (B, C, H', W')\n",
        "        b, c, h, w = conv.size()\n",
        "        conv = conv.permute(3, 0, 2, 1)      # (W', B, H', C)\n",
        "        conv = conv.contiguous().view(w, b, h*c)  # (W', B, h*c)\n",
        "        rnn_out, _ = self.rnn(conv)     # (W', B, 2*hidden)\n",
        "        logits = self.fc(rnn_out)       # (W', B, num_classes)\n",
        "        return logits.log_softmax(2)    # CTC expects log-probs\n",
        "\n",
        "num_classes = len(char_list) + 1  # +1 for blank (index 0)\n",
        "model = CRNN(IMG_H, num_classes=num_classes).to(device)\n",
        "print(model)\n",
        "\n",
        "# ---------------- Loss & optimizer ----------------\n",
        "ctc_loss = nn.CTCLoss(blank=BLANK_IDX, zero_infinity=True)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "\n",
        "# ---------------- Decoder & metrics ----------------\n",
        "def ctc_greedy_decode(preds_log_softmax):\n",
        "    preds = preds_log_softmax.detach().cpu().numpy()  # (T,B,C)\n",
        "    T, B, C = preds.shape\n",
        "    texts = []\n",
        "    for b in range(B):\n",
        "        seq = []\n",
        "        last = -1\n",
        "        for t in range(T):\n",
        "            idx = int(preds[t, b].argmax())\n",
        "            if idx != last and idx != BLANK_IDX:\n",
        "                seq.append(idx_to_char.get(idx, \"\"))\n",
        "            last = idx\n",
        "        texts.append(\"\".join(seq))\n",
        "    return texts\n",
        "\n",
        "def levenshtein(a, b):\n",
        "    la, lb = len(a), len(b)\n",
        "    if la == 0: return lb\n",
        "    if lb == 0: return la\n",
        "    dp = list(range(lb+1))\n",
        "    for i in range(1, la+1):\n",
        "        prev = dp[0]\n",
        "        dp[0] = i\n",
        "        for j in range(1, lb+1):\n",
        "            cur = dp[j]\n",
        "            if a[i-1] == b[j-1]:\n",
        "                dp[j] = prev\n",
        "            else:\n",
        "                dp[j] = 1 + min(prev, dp[j-1], dp[j])\n",
        "            prev = cur\n",
        "    return dp[lb]\n",
        "\n",
        "# ---------------- Evaluation helper (returns detailed lists) ----------------\n",
        "def evaluate_collect(loader, model, collect_examples=False, max_examples=None):\n",
        "    model.eval()\n",
        "    tot_loss = 0.0\n",
        "    tot_samples = 0\n",
        "    exact_matches = 0\n",
        "    total_chars = 0\n",
        "    total_char_errors = 0\n",
        "\n",
        "    records = []  # will store tuples (pred, target, ed, target_len, pil_image) if requested\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, targets_concat, target_lengths, target_strs, pil_images in loader:\n",
        "            images = images.to(device)\n",
        "            B = images.size(0)\n",
        "            logits = model(images)               # (T,B,C)\n",
        "            T, _, _ = logits.shape\n",
        "            input_lengths = torch.full((B,), T, dtype=torch.long).to(device)\n",
        "            targets = targets_concat.to(device)\n",
        "            loss = ctc_loss(logits, targets, input_lengths, target_lengths.to(device))\n",
        "            tot_loss += loss.item() * B\n",
        "            tot_samples += B\n",
        "\n",
        "            preds = ctc_greedy_decode(logits)\n",
        "            for i, (pred, target) in enumerate(zip(preds, target_strs)):\n",
        "                ed = levenshtein(pred, target)\n",
        "                total_char_errors += ed\n",
        "                total_chars += max(1, len(target))\n",
        "                if pred == target:\n",
        "                    exact_matches += 1\n",
        "                rec = (pred, target, ed, len(target))\n",
        "                if collect_examples:\n",
        "                    rec = rec + (pil_images[i],)\n",
        "                records.append(rec)\n",
        "\n",
        "            if max_examples and len(records) >= max_examples:\n",
        "                break\n",
        "\n",
        "    avg_loss = tot_loss / max(1, tot_samples)\n",
        "    exact_acc = exact_matches / max(1, tot_samples)\n",
        "    cer = total_char_errors / max(1, total_chars)\n",
        "    return avg_loss, exact_acc, cer, total_chars, total_char_errors, records\n",
        "\n",
        "# ---------------- Training loop ----------------\n",
        "train_losses = []\n",
        "val_losses = []\n",
        "val_accs = []\n",
        "val_cers = []\n",
        "\n",
        "print(\"Starting training...\")\n",
        "for epoch in range(1, EPOCHS+1):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    total_seen = 0\n",
        "    pbar = tqdm(train_loader, desc=f\"Epoch {epoch}/{EPOCHS}\", leave=False)\n",
        "    for images, targets_concat, target_lengths, target_strs, pil_images in pbar:\n",
        "        images = images.to(device)\n",
        "        B = images.size(0)\n",
        "        optimizer.zero_grad()\n",
        "        logits = model(images)   # (T,B,C)\n",
        "        T, _, _ = logits.shape\n",
        "        input_lengths = torch.full((B,), T, dtype=torch.long).to(device)\n",
        "        loss = ctc_loss(logits, targets_concat.to(device), input_lengths, target_lengths.to(device))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item() * B\n",
        "        total_seen += B\n",
        "        pbar.set_postfix({\"batch_loss\": f\"{loss.item():.4f}\"})\n",
        "    epoch_train_loss = running_loss / max(1, len(train_ds))\n",
        "    train_losses.append(epoch_train_loss)\n",
        "\n",
        "    # validation\n",
        "    val_loss, val_acc, val_cer, _, _, _ = evaluate_collect(val_loader, model, collect_examples=False)\n",
        "    val_losses.append(val_loss)\n",
        "    val_accs.append(val_acc)\n",
        "    val_cers.append(val_cer)\n",
        "\n",
        "    print(f\"Epoch {epoch}  TrainLoss: {epoch_train_loss:.4f}  ValLoss: {val_loss:.4f}  ValAcc: {val_acc*100:.2f}%  ValCER: {val_cer:.4f}\")\n",
        "\n",
        "# ---------------- Plot training curves ----------------\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(range(1, len(train_losses)+1), train_losses, label=\"train_loss\")\n",
        "plt.plot(range(1, len(val_losses)+1), val_losses, label=\"val_loss\")\n",
        "plt.xlabel(\"Epoch\"); plt.title(\"Loss\"); plt.legend()\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(range(1, len(val_accs)+1), [a*100 for a in val_accs], label=\"val_exact_acc_%\")\n",
        "plt.xlabel(\"Epoch\"); plt.title(\"Validation Exact-match Accuracy (%)\"); plt.legend()\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------- Detailed TEST evaluation ----------------\n",
        "test_loss, test_acc, test_cer, total_chars, total_char_errors, test_records = evaluate_collect(test_loader, model, collect_examples=True)\n",
        "\n",
        "char_accuracy = (total_chars - total_char_errors) / max(1, total_chars)\n",
        "\n",
        "print(\"\\nFINAL EVALUATION ON TEST SET\")\n",
        "print(f\"Test Loss: {test_loss:.4f}\")\n",
        "print(f\"Test Exact-match Accuracy: {test_acc*100:.2f}%\")\n",
        "print(f\"Test CER (char error rate): {test_cer:.4f}\")\n",
        "print(f\"Test Character Accuracy: {char_accuracy*100:.2f}% (i.e., chars correct / total chars)\")\n",
        "\n",
        "# ---------------- Save CSV of predictions ----------------\n",
        "df = pd.DataFrame(test_records, columns=[\"predicted\", \"target\", \"edit_distance\", \"target_length\", \"pil_image\"])\n",
        "# drop PIL image before saving CSV; but keep it in-memory for example export\n",
        "df_to_save = df.drop(columns=[\"pil_image\"])\n",
        "csv_path = \"test_predictions.csv\"\n",
        "df_to_save.to_csv(csv_path, index=False)\n",
        "print(f\"\\nSaved test predictions to: {csv_path}\")\n",
        "display(df_to_save.head(20))\n",
        "\n",
        "# ---------------- Histogram of edit distances ----------------\n",
        "eds = df[\"edit_distance\"].astype(int).values\n",
        "plt.figure(figsize=(6,4))\n",
        "plt.hist(eds, bins=range(0, max(eds)+2), align=\"left\")\n",
        "plt.xlabel(\"Edit distance (Levenshtein)\")\n",
        "plt.ylabel(\"Number of samples\")\n",
        "plt.title(\"Histogram of edit distances on test set\")\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------- Exact-match accuracy by word length ----------------\n",
        "grouped = df.groupby(\"target_length\").apply(lambda x: (x[\"predicted\"]==x[\"target\"]).mean())\n",
        "lengths = grouped.index.tolist()\n",
        "accs_by_len = grouped.values.tolist()\n",
        "plt.figure(figsize=(7,4))\n",
        "plt.bar(lengths, [a*100 for a in accs_by_len])\n",
        "plt.xlabel(\"Target word length\")\n",
        "plt.ylabel(\"Exact-match accuracy (%)\")\n",
        "plt.title(\"Exact-match accuracy by word length (test set)\")\n",
        "plt.xticks(lengths)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# ---------------- Save worst examples (highest edit distance) ----------------\n",
        "out_dir = Path(\"test_examples\")\n",
        "if out_dir.exists():\n",
        "    shutil.rmtree(out_dir)\n",
        "out_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# sort by edit distance descending, take top N worst\n",
        "N_worst = 10\n",
        "df_sorted = df.sort_values(by=\"edit_distance\", ascending=False).head(N_worst).reset_index(drop=True)\n",
        "\n",
        "for i, row in df_sorted.iterrows():\n",
        "    pil_img = row[\"pil_image\"]\n",
        "    pred = row[\"predicted\"]\n",
        "    target = row[\"target\"]\n",
        "    ed = int(row[\"edit_distance\"])\n",
        "    # create a new RGB image with extra space below to write text\n",
        "    canvas = Image.new(\"RGB\", (IMG_W, IMG_H+30), color=(255,255,255))\n",
        "    canvas.paste(pil_img.convert(\"RGB\"), (0,0))\n",
        "    draw = ImageDraw.Draw(canvas)\n",
        "    # choose a font for overlay if available\n",
        "    try:\n",
        "        font_path = downloaded_fonts[0] if downloaded_fonts else None\n",
        "        font_small = ImageFont.truetype(font_path, size=12) if font_path else ImageFont.load_default()\n",
        "    except:\n",
        "        font_small = ImageFont.load_default()\n",
        "    text = f\"P:{pred}  T:{target}  ED:{ed}\"\n",
        "    draw.text((4, IMG_H+4), text, fill=(0,0,0), font=font_small)\n",
        "    save_path = out_dir / f\"worst_{i+1}_ed{ed}.png\"\n",
        "    canvas.save(save_path)\n",
        "print(f\"\\nSaved top {N_worst} worst examples to folder: {out_dir.resolve()}\")\n",
        "\n",
        "# display a few worst examples inline (if in notebook)\n",
        "from IPython.display import display as ipydisplay\n",
        "print(\"\\nTop worst examples (display):\")\n",
        "for p in sorted(out_dir.iterdir())[:N_worst]:\n",
        "    print(p.name)\n",
        "    ipydisplay(Image.open(p))\n",
        "\n",
        "# ---------------- Show some random examples from test set ----------------\n",
        "print(\"\\nSome random test set predictions (predicted -> target):\")\n",
        "sample = df.sample(min(20, len(df)), random_state=seed).reset_index(drop=True)\n",
        "for i, r in sample.head(20).iterrows():\n",
        "    print(f\"{i+1:2d}. {r['predicted']}  ->  {r['target']}  (ED={r['edit_distance']})\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2DsPJyy2CIHE",
        "outputId": "73897a5f-dd39-4179-d8cc-7490612869a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Nov 24 18:04:10 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   65C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n",
            "A module that was compiled using NumPy 1.x cannot be run in\n",
            "NumPy 2.0.2 as it may crash. To support both 1.x and 2.x\n",
            "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
            "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
            "\n",
            "If you are a user of the module, the easiest solution will be to\n",
            "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
            "We expect that some modules will need time to support NumPy 2.\n",
            "\n",
            "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
            "  File \"<frozen runpy>\", line 88, in _run_code\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/colab_kernel_launcher.py\", line 37, in <module>\n",
            "    ColabKernelApp.launch_instance()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/traitlets/config/application.py\", line 992, in launch_instance\n",
            "    app.start()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelapp.py\", line 712, in start\n",
            "    self.io_loop.start()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/tornado/platform/asyncio.py\", line 211, in start\n",
            "    self.asyncio_loop.run_forever()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 645, in run_forever\n",
            "    self._run_once()\n",
            "  File \"/usr/lib/python3.12/asyncio/base_events.py\", line 1999, in _run_once\n",
            "    handle._run()\n",
            "  File \"/usr/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
            "    self._context.run(self._callback, *self._args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 510, in dispatch_queue\n",
            "    await self.process_one()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 499, in process_one\n",
            "    await dispatch(*args)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 406, in dispatch_shell\n",
            "    await result\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/kernelbase.py\", line 730, in execute_request\n",
            "    reply_content = await reply_content\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/ipkernel.py\", line 383, in do_execute\n",
            "    res = shell.run_cell(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/ipykernel/zmqshell.py\", line 528, in run_cell\n",
            "    return super().run_cell(*args, **kwargs)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 2975, in run_cell\n",
            "    result = self._run_cell(\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3030, in _run_cell\n",
            "    return runner(coro)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/async_helpers.py\", line 78, in _pseudo_sync_runner\n",
            "    coro.send(None)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3257, in run_cell_async\n",
            "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3473, in run_ast_nodes\n",
            "    if (await self.run_code(code, result,  async_=asy)):\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/IPython/core/interactiveshell.py\", line 3553, in run_code\n",
            "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
            "  File \"/tmp/ipython-input-683670041.py\", line 17, in <cell line: 0>\n",
            "    import cv2\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py\", line 54, in create_module\n",
            "    loader.exec_module(module)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/cv2/__init__.py\", line 181, in <module>\n",
            "    bootstrap()\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/cv2/__init__.py\", line 153, in bootstrap\n",
            "    native_module = importlib.import_module(\"cv2\")\n",
            "  File \"/usr/lib/python3.12/importlib/__init__.py\", line 90, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "  File \"/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py\", line 51, in create_module\n",
            "    module = importlib.util.module_from_spec(spec)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "_ARRAY_API not found",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;31mAttributeError\u001b[0m: _ARRAY_API not found"
          ]
        },
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "numpy.core.multiarray failed to import",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-683670041.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m     52\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m         \u001b[0mloader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexec_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     55\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_code_callback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpreviously_loaded\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/cv2/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m \u001b[0mbootstrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/cv2/__init__.py\u001b[0m in \u001b[0;36mbootstrap\u001b[0;34m()\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0mpy_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cv2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m     \u001b[0mnative_module\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimport_module\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"cv2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m     \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"cv2\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpy_module\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.12/importlib/__init__.py\u001b[0m in \u001b[0;36mimport_module\u001b[0;34m(name, package)\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m             \u001b[0mlevel\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_bootstrap\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gcd_import\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlevel\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpackage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlevel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/google/colab/_import_hooks/_hook_injector.py\u001b[0m in \u001b[0;36mcreate_module\u001b[0;34m(self, spec)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mspec\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m       \u001b[0mloader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mspec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m       \u001b[0mmodule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimportlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule_from_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mloader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfullname\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: numpy.core.multiarray failed to import",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}